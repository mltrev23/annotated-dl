<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="content-type" content="text/html;charset=utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <meta name="description" content="A PyTorch implementation/tutorial of PonderNet: Learning to Ponder."/>

    <meta name="twitter:card" content="summary"/>
    <meta name="twitter:image:src" content="https://avatars1.githubusercontent.com/u/64068543?s=400&amp;v=4"/>
    <meta name="twitter:title" content="PonderNet: Learning to Ponder"/>
    <meta name="twitter:description" content="A PyTorch implementation/tutorial of PonderNet: Learning to Ponder."/>
    <meta name="twitter:site" content="@labmlai"/>
    <meta name="twitter:creator" content="@labmlai"/>

    <meta property="og:url" content="https://nn.labml.ai/adaptive_computation/ponder_net/index.html"/>
    <meta property="og:title" content="PonderNet: Learning to Ponder"/>
    <meta property="og:image" content="https://avatars1.githubusercontent.com/u/64068543?s=400&amp;v=4"/>
    <meta property="og:site_name" content="LabML Neural Networks"/>
    <meta property="og:type" content="object"/>
    <meta property="og:title" content="PonderNet: Learning to Ponder"/>
    <meta property="og:description" content="A PyTorch implementation/tutorial of PonderNet: Learning to Ponder."/>

    <title>PonderNet: Learning to Ponder</title>
    <link rel="shortcut icon" href="/icon.png"/>
    <link rel="stylesheet" href="../../pylit.css">
    <link rel="canonical" href="https://nn.labml.ai/adaptive_computation/ponder_net/index.html"/>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-4V3HC8HBLH"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-4V3HC8HBLH');
    </script>
</head>
<body>
<div id='container'>
    <div id="background"></div>
    <div class='section'>
        <div class='docs'>
            <p>
                <a class="parent" href="/">home</a>
                <a class="parent" href="../index.html">adaptive_computation</a>
                <a class="parent" href="index.html">ponder_net</a>
            </p>
            <p>

                <a href="https://github.com/labmlai/annotated_deep_learning_paper_implementations/tree/master/labml_nn/adaptive_computation/ponder_net/__init__.py">
                    <img alt="Github"
                         src="https://img.shields.io/github/stars/labmlai/annotated_deep_learning_paper_implementations?style=social"
                         style="max-width:100%;"/></a>
                <a href="https://twitter.com/labmlai"
                   rel="nofollow">
                    <img alt="Twitter"
                         src="https://img.shields.io/twitter/follow/labmlai?style=social"
                         style="max-width:100%;"/></a>
            </p>
        </div>
    </div>
    <div class='section' id='section-0'>
        <div class='docs doc-strings'>
                <div class='section-link'>
                    <a href='#section-0'>#</a>
                </div>
                <h1>PonderNet: Learning to Ponder</h1>
<p>This is a <a href="https://pytorch.org">PyTorch</a> implementation of the paper
<a href="https://papers.labml.ai/paper/2107.05407">PonderNet: Learning to Ponder</a>.</p>
<p>PonderNet adapts the computation based on the input.
It changes the number of steps to take on a recurrent network based on the input.
PonderNet learns this with end-to-end gradient descent.</p>
<p>PonderNet has a step function of the form</p>
<p>
<script type="math/tex; mode=display">\hat{y}_n, h_{n+1}, \lambda_n = s(x, h_n)</script>
</p>
<p>where $x$ is the input, $h_n$ is the state, $\hat{y}_n$ is the prediction at step $n$,
and $\lambda_n$ is the probability of halting (stopping) at current step.</p>
<p>$s$ can be any neural network (e.g. LSTM, MLP, GRU, Attention layer).</p>
<p>The unconditioned probability of halting at step $n$ is then,</p>
<p>
<script type="math/tex; mode=display">p_n = \lambda_n \prod_{j=1}^{n-1} (1 - \lambda_j)</script>
</p>
<p>That is the probability of not being halted at any of the previous steps and halting at step $n$.</p>
<p>During inference, we halt by sampling based on the halting probability $\lambda_n$
 and get the prediction at the halting layer $\hat{y}_n$ as the final output.</p>
<p>During training, we get the predictions from all the layers and calculate the losses for each of them.
And then take the weighted average of the losses based on the probabilities of getting halted at each layer
$p_n$.</p>
<p>The step function is applied to a maximum number of steps donated by $N$.</p>
<p>The overall loss of PonderNet is
<script type="math/tex; mode=display">\begin{align}
L &= L_{Rec} + \beta L_{Reg} \\
L_{Rec} &= \sum_{n=1}^N p_n \mathcal{L}(y, \hat{y}_n) \\
L_{Reg} &= \mathop{KL} \Big(p_n \Vert p_G(\lambda_p) \Big)
\end{align}</script>
</p>
<p>$\mathcal{L}$ is the normal loss function between target $y$ and prediction $\hat{y}_n$.</p>
<p>$\mathop{KL}$ is the <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullbackâ€“Leibler divergence</a>.</p>
<p>$p_G$ is the <a href="https://en.wikipedia.org/wiki/Geometric_distribution">Geometric distribution</a> parameterized by
$\lambda_p$. <em>$\lambda_p$ has nothing to do with $\lambda_n$; we are just sticking to same notation as the paper</em>.
<script type="math/tex; mode=display">Pr_{p_G(\lambda_p)}(X = k) = (1 - \lambda_p)^k \lambda_p</script>.</p>
<p>The regularization loss biases the network towards taking $\frac{1}{\lambda_p}$ steps and incentivizes
 non-zero probabilities for all steps; i.e. promotes exploration.</p>
<p>Here is the <a href="experiment.html">training code <code>experiment.py</code></a> to train a PonderNet on <a href="../parity.html">Parity Task</a>.</p>
<p><a href="https://app.labml.ai/run/bfdcea24fa8f11eb89a54df6f6e862b9"><img alt="View Run" src="https://img.shields.io/badge/labml-experiment-brightgreen" /></a></p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">64</span><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span>
<span class="lineno">65</span>
<span class="lineno">66</span><span class="kn">import</span> <span class="nn">torch</span>
<span class="lineno">67</span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="lineno">68</span>
<span class="lineno">69</span><span class="kn">from</span> <span class="nn">labml_helpers.module</span> <span class="kn">import</span> <span class="n">Module</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-1'>
        <div class='docs doc-strings'>
                <div class='section-link'>
                    <a href='#section-1'>#</a>
                </div>
                <h2>PonderNet with GRU for Parity Task</h2>
<p>This is a simple model that uses a <a href="https://pytorch.org/docs/stable/generated/torch.nn.GRUCell.html">GRU Cell</a>
as the step function.</p>
<p>This model is for the <a href="../parity.html">Parity Task</a> where the input is a vector of <code>n_elems</code>.
Each element of the vector is either <code>0</code>, <code>1</code> or <code>-1</code> and the output is the parity
- a binary value that is true if the number of <code>1</code>s is odd and false otherwise.</p>
<p>The prediction of the model is the log probability of the parity being $1$.</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">72</span><span class="k">class</span> <span class="nc">ParityPonderGRU</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-2'>
        <div class='docs doc-strings'>
                <div class='section-link'>
                    <a href='#section-2'>#</a>
                </div>
                <ul>
<li><code>n_elems</code> is the number of elements in the input vector</li>
<li><code>n_hidden</code> is the state vector size of the GRU</li>
<li><code>max_steps</code> is the maximum number of steps $N$</li>
</ul>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">86</span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_elems</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">max_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-3'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-3'>#</a>
                </div>
                
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">92</span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="lineno">93</span>
<span class="lineno">94</span>        <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">=</span> <span class="n">max_steps</span>
<span class="lineno">95</span>        <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span> <span class="o">=</span> <span class="n">n_hidden</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-4'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-4'>#</a>
                </div>
                <p>GRU
<script type="math/tex; mode=display">h_{n+1} = s_h(x, h_n)</script>
</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">99</span>        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRUCell</span><span class="p">(</span><span class="n">n_elems</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">)</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-5'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-5'>#</a>
                </div>
                <p>
<script type="math/tex; mode=display">\hat{y}_n = s_y(h_n)</script>
We could use a layer that takes the concatenation of $h$ and $x$ as input
but we went with this for simplicity.</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">103</span>        <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-6'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-6'>#</a>
                </div>
                <p>
<script type="math/tex; mode=display">\lambda_n = s_\lambda(h_n)</script>
</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">105</span>        <span class="bp">self</span><span class="o">.</span><span class="n">lambda_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="lineno">106</span>        <span class="bp">self</span><span class="o">.</span><span class="n">lambda_prob</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-7'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-7'>#</a>
                </div>
                <p>An option to set during inference so that computation is actually halted at inference time</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">108</span>        <span class="bp">self</span><span class="o">.</span><span class="n">is_halt</span> <span class="o">=</span> <span class="kc">False</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-8'>
        <div class='docs doc-strings'>
                <div class='section-link'>
                    <a href='#section-8'>#</a>
                </div>
                <ul>
<li><code>x</code> is the input of shape <code>[batch_size, n_elems]</code></li>
</ul>
<p>This outputs a tuple of four tensors:</p>
<ol>
<li>$p_1 \dots p_N$ in a tensor of shape <code>[N, batch_size]</code></li>
<li>$\hat{y}_1 \dots \hat{y}_N$ in a tensor of shape <code>[N, batch_size]</code> - the log probabilities of the parity being $1$</li>
<li>$p_m$ of shape <code>[batch_size]</code></li>
<li>$\hat{y}_m$ of shape <code>[batch_size]</code> where the computation was halted at step $m$</li>
</ol>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">110</span>    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-9'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-9'>#</a>
                </div>
                
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">123</span>        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-10'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-10'>#</a>
                </div>
                <p>We get initial state $h_1 = s_h(x)$</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">126</span>        <span class="n">h</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">))</span>
<span class="lineno">127</span>        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-11'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-11'>#</a>
                </div>
                <p>Lists to store $p_1 \dots p_N$ and $\hat{y}_1 \dots \hat{y}_N$</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">130</span>        <span class="n">p</span> <span class="o">=</span> <span class="p">[]</span>
<span class="lineno">131</span>        <span class="n">y</span> <span class="o">=</span> <span class="p">[]</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-12'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-12'>#</a>
                </div>
                <p>$\prod_{j=1}^{n-1} (1 - \lambda_j)$</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">133</span>        <span class="n">un_halted_prob</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">new_ones</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,))</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-13'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-13'>#</a>
                </div>
                <p>A vector to maintain which samples has halted computation</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">136</span>        <span class="n">halted</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,))</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-14'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-14'>#</a>
                </div>
                <p>$p_m$ and $\hat{y}_m$ where the computation was halted at step $m$</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">138</span>        <span class="n">p_m</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,))</span>
<span class="lineno">139</span>        <span class="n">y_m</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,))</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-15'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-15'>#</a>
                </div>
                <p>Iterate for $N$ steps</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">142</span>        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-16'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-16'>#</a>
                </div>
                <p>The halting probability $\lambda_N = 1$ for the last step</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">144</span>            <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span><span class="p">:</span>
<span class="lineno">145</span>                <span class="n">lambda_n</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">new_ones</span><span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-17'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-17'>#</a>
                </div>
                <p>$\lambda_n = s_\lambda(h_n)$</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">147</span>            <span class="k">else</span><span class="p">:</span>
<span class="lineno">148</span>                <span class="n">lambda_n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_layer</span><span class="p">(</span><span class="n">h</span><span class="p">))[:,</span> <span class="mi">0</span><span class="p">]</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-18'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-18'>#</a>
                </div>
                <p>$\hat{y}_n = s_y(h_n)$</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">150</span>            <span class="n">y_n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">h</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-19'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-19'>#</a>
                </div>
                <p>
<script type="math/tex; mode=display">p_n = \lambda_n \prod_{j=1}^{n-1} (1 - \lambda_j)</script>
</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">153</span>            <span class="n">p_n</span> <span class="o">=</span> <span class="n">un_halted_prob</span> <span class="o">*</span> <span class="n">lambda_n</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-20'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-20'>#</a>
                </div>
                <p>Update $\prod_{j=1}^{n-1} (1 - \lambda_j)$</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">155</span>            <span class="n">un_halted_prob</span> <span class="o">=</span> <span class="n">un_halted_prob</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">lambda_n</span><span class="p">)</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-21'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-21'>#</a>
                </div>
                <p>Halt based on halting probability $\lambda_n$</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">158</span>            <span class="n">halt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">lambda_n</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">halted</span><span class="p">)</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-22'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-22'>#</a>
                </div>
                <p>Collect $p_n$ and $\hat{y}_n$</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">161</span>            <span class="n">p</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p_n</span><span class="p">)</span>
<span class="lineno">162</span>            <span class="n">y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_n</span><span class="p">)</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-23'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-23'>#</a>
                </div>
                <p>Update $p_m$ and $\hat{y}_m$ based on what was halted at current step $n$</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">165</span>            <span class="n">p_m</span> <span class="o">=</span> <span class="n">p_m</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">halt</span><span class="p">)</span> <span class="o">+</span> <span class="n">p_n</span> <span class="o">*</span> <span class="n">halt</span>
<span class="lineno">166</span>            <span class="n">y_m</span> <span class="o">=</span> <span class="n">y_m</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">halt</span><span class="p">)</span> <span class="o">+</span> <span class="n">y_n</span> <span class="o">*</span> <span class="n">halt</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-24'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-24'>#</a>
                </div>
                <p>Update halted samples</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">169</span>            <span class="n">halted</span> <span class="o">=</span> <span class="n">halted</span> <span class="o">+</span> <span class="n">halt</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-25'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-25'>#</a>
                </div>
                <p>Get next state $h_{n+1} = s_h(x, h_n)$</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">171</span>            <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-26'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-26'>#</a>
                </div>
                <p>Stop the computation if all samples have halted</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">174</span>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_halt</span> <span class="ow">and</span> <span class="n">halted</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">==</span> <span class="n">batch_size</span><span class="p">:</span>
<span class="lineno">175</span>                <span class="k">break</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-27'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-27'>#</a>
                </div>
                
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">178</span>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">p</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">p_m</span><span class="p">,</span> <span class="n">y_m</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-28'>
        <div class='docs doc-strings'>
                <div class='section-link'>
                    <a href='#section-28'>#</a>
                </div>
                <h2>Reconstruction loss</h2>
<p>
<script type="math/tex; mode=display">L_{Rec} = \sum_{n=1}^N p_n \mathcal{L}(y, \hat{y}_n)</script>
</p>
<p>$\mathcal{L}$ is the normal loss function between target $y$ and prediction $\hat{y}_n$.</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">181</span><span class="k">class</span> <span class="nc">ReconstructionLoss</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-29'>
        <div class='docs doc-strings'>
                <div class='section-link'>
                    <a href='#section-29'>#</a>
                </div>
                <ul>
<li><code>loss_func</code> is the loss function $\mathcal{L}$</li>
</ul>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">190</span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-30'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-30'>#</a>
                </div>
                
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">194</span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="lineno">195</span>        <span class="bp">self</span><span class="o">.</span><span class="n">loss_func</span> <span class="o">=</span> <span class="n">loss_func</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-31'>
        <div class='docs doc-strings'>
                <div class='section-link'>
                    <a href='#section-31'>#</a>
                </div>
                <ul>
<li><code>p</code> is $p_1 \dots p_N$ in a tensor of shape <code>[N, batch_size]</code></li>
<li><code>y_hat</code> is $\hat{y}_1 \dots \hat{y}_N$ in a tensor of shape <code>[N, batch_size, ...]</code></li>
<li><code>y</code> is the target of shape <code>[batch_size, ...]</code></li>
</ul>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">197</span>    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-32'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-32'>#</a>
                </div>
                <p>The total $\sum_{n=1}^N p_n \mathcal{L}(y, \hat{y}_n)$</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">205</span>        <span class="n">total_loss</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">new_tensor</span><span class="p">(</span><span class="mf">0.</span><span class="p">)</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-33'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-33'>#</a>
                </div>
                <p>Iterate upto $N$</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">207</span>        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-34'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-34'>#</a>
                </div>
                <p>$p_n \mathcal{L}(y, \hat{y}_n)$ for each sample and the mean of them</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">209</span>            <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_func</span><span class="p">(</span><span class="n">y_hat</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">y</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-35'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-35'>#</a>
                </div>
                <p>Add to total loss</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">211</span>            <span class="n">total_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">+</span> <span class="n">loss</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-36'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-36'>#</a>
                </div>
                
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">214</span>        <span class="k">return</span> <span class="n">total_loss</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-37'>
        <div class='docs doc-strings'>
                <div class='section-link'>
                    <a href='#section-37'>#</a>
                </div>
                <h2>Regularization loss</h2>
<p>
<script type="math/tex; mode=display">L_{Reg} = \mathop{KL} \Big(p_n \Vert p_G(\lambda_p) \Big)</script>
</p>
<p>$\mathop{KL}$ is the <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullbackâ€“Leibler divergence</a>.</p>
<p>$p_G$ is the <a href="https://en.wikipedia.org/wiki/Geometric_distribution">Geometric distribution</a> parameterized by
$\lambda_p$. <em>$\lambda_p$ has nothing to do with $\lambda_n$; we are just sticking to same notation as the paper</em>.
<script type="math/tex; mode=display">Pr_{p_G(\lambda_p)}(X = k) = (1 - \lambda_p)^k \lambda_p</script>.</p>
<p>The regularization loss biases the network towards taking $\frac{1}{\lambda_p}$ steps and incentivies non-zero probabilities
for all steps; i.e. promotes exploration.</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">217</span><span class="k">class</span> <span class="nc">RegularizationLoss</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-38'>
        <div class='docs doc-strings'>
                <div class='section-link'>
                    <a href='#section-38'>#</a>
                </div>
                <ul>
<li><code>lambda_p</code> is $\lambda_p$ - the success probability of geometric distribution</li>
<li><code>max_steps</code> is the highest $N$; we use this to pre-compute $p_G(\lambda_p)$</li>
</ul>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">233</span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambda_p</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">max_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1_000</span><span class="p">):</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-39'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-39'>#</a>
                </div>
                
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">238</span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-40'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-40'>#</a>
                </div>
                <p>Empty vector to calculate $p_G(\lambda_p)$</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">241</span>        <span class="n">p_g</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">max_steps</span><span class="p">,))</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-41'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-41'>#</a>
                </div>
                <p>$(1 - \lambda_p)^k$</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">243</span>        <span class="n">not_halted</span> <span class="o">=</span> <span class="mf">1.</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-42'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-42'>#</a>
                </div>
                <p>Iterate upto <code>max_steps</code></p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">245</span>        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_steps</span><span class="p">):</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-43'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-43'>#</a>
                </div>
                <p>
<script type="math/tex; mode=display">Pr_{p_G(\lambda_p)}(X = k) = (1 - \lambda_p)^k \lambda_p</script>
</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">247</span>            <span class="n">p_g</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">not_halted</span> <span class="o">*</span> <span class="n">lambda_p</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-44'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-44'>#</a>
                </div>
                <p>Update $(1 - \lambda_p)^k$</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">249</span>            <span class="n">not_halted</span> <span class="o">=</span> <span class="n">not_halted</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">lambda_p</span><span class="p">)</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-45'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-45'>#</a>
                </div>
                <p>Save $Pr_{p_G(\lambda_p)}$</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">252</span>        <span class="bp">self</span><span class="o">.</span><span class="n">p_g</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">p_g</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-46'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-46'>#</a>
                </div>
                <p>KL-divergence loss</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">255</span>        <span class="bp">self</span><span class="o">.</span><span class="n">kl_div</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">KLDivLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;batchmean&#39;</span><span class="p">)</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-47'>
        <div class='docs doc-strings'>
                <div class='section-link'>
                    <a href='#section-47'>#</a>
                </div>
                <ul>
<li><code>p</code> is $p_1 \dots p_N$ in a tensor of shape <code>[N, batch_size]</code></li>
</ul>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">257</span>    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-48'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-48'>#</a>
                </div>
                <p>Transpose <code>p</code> to <code>[batch_size, N]</code></p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">262</span>        <span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-49'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-49'>#</a>
                </div>
                <p>Get $Pr_{p_G(\lambda_p)}$ upto $N$ and expand it across the batch dimension</p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">264</span>        <span class="n">p_g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_g</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">p</span><span class="p">)</span></pre></div>
            </div>
        </div>
    <div class='section' id='section-50'>
            <div class='docs'>
                <div class='section-link'>
                    <a href='#section-50'>#</a>
                </div>
                <p>Calculate the KL-divergence.
<em>The <a href="https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html">PyTorch KL-divergence</a>
implementation accepts log probabilities.</em></p>
            </div>
            <div class='code'>
                <div class="highlight"><pre><span class="lineno">269</span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">kl_div</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">log</span><span class="p">(),</span> <span class="n">p_g</span><span class="p">)</span></pre></div>
            </div>
        </div>
    </div>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML">
</script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'] ],
            displayMath: [ ['$$','$$'] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": { fonts: ["TeX"] }
    });
</script>
<script>
    function handleImages() {
        var images = document.querySelectorAll('p>img')

        console.log(images);
        for (var i = 0; i < images.length; ++i) {
            handleImage(images[i])
        }
    }

    function handleImage(img) {
        img.parentElement.style.textAlign = 'center'

        var modal = document.createElement('div')
        modal.id = 'modal'

        var modalContent = document.createElement('div')
        modal.appendChild(modalContent)

        var modalImage = document.createElement('img')
        modalContent.appendChild(modalImage)

        var span = document.createElement('span')
        span.classList.add('close')
        span.textContent = 'x'
        modal.appendChild(span)

        img.onclick = function () {
            console.log('clicked')
            document.body.appendChild(modal)
            modalImage.src = img.src
        }

        span.onclick = function () {
            document.body.removeChild(modal)
        }
    }

    handleImages()
</script>
</body>
</html>