{
 "<p> Splits hidden_size dim into attn_head_size and num_heads</p>\n": "<p> Splits hidden_size dim into attn_head_size and num_heads</p>\n",
 "<p>Add position embeddings </p>\n": "<p>Add position embeddings </p>\n",
 "<p>Final normalization </p>\n": "<p>Final normalization </p>\n",
 "<p>Get logits from projection layer </p>\n": "<p>Get logits from projection layer </p>\n",
 "<p>Get position embeddings </p>\n": "<p>Get position embeddings </p>\n",
 "<p>Get position ids </p>\n": "<p>Get position ids </p>\n",
 "<p>Get token embeddings </p>\n": "<p>Get token embeddings </p>\n",
 "<p>Run through transformer blocks </p>\n": "<p>Run through transformer blocks </p>\n",
 "<p>lin1 </p>\n": "<p>lin1 </p>\n",
 "<p>lin2 </p>\n": "<p>lin2 </p>\n",
 "<p>out </p>\n": "<p>out </p>\n",
 "<p>qkv </p>\n": "<p>qkv </p>\n",
 "<ul><li><span translate=no>_^_0_^_</span>  has shape <span translate=no>_^_1_^_</span></li></ul>\n": "<ul><li><span translate=no>_^_0_^_</span>  has shape <span translate=no>_^_1_^_</span></li></ul>\n",
 "gpt2.py": "gpt2.py"
}